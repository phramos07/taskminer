* Kreaseck00 - Limits of Task-based Parallelism in Irregular Applications
[Insights]
- Speculative Task Parallelism.
- Use of futures.
- Execute task speculatively, based on profiling, and rollback if necessary.
[Similarities]
- Search for parallelism in irregular loops.
[Differences]
- We use a concrete execution model. They use a hypothetical machine.
- We implement actual parallelization.
- We do not do speculation.

* Li12 - Automatic Extraction of Coarse-Grained Data-Flow Threads from
         Imperative Programs
[Insights]
- Static analysis to find data-flow parallelism in imperative programs.
- Optimizations to coarsen the grain of parallelism
[Differences]
- Does not seem to have support of the runtime?
- Does not handle pointers and aggregate types.

* Pingali11 - The Tao of Parallelism in Algorithms
[Insights]
- Parallelism in irregular applications depends on data.
- Dependence graph is not able to find this parallelism.
- Proposes new primitives to code algorithms.
[Similarities]
- Seek to find parallelism in irregular applications.
- "Dependences between activities in irregular algorithms are usu- ally complex
  functions of runtime data values, so they cannot be usefully captured by a
  static dependence graph."
- We agree with the above sentence. Our approach uses a static analysis to
  detect tasks, but it is up to the runtime if we can run that task in
  parallel with other tasks already in flight.
- We can use Delaunay Triangulation as an example of program that we can
  parallelize.
[Differences]
- Requires a new language, or at least new abstractions, to write parallel
  algorithms. Our approach should be totally automatic.
- Our approach still relies on static dependance graphs to find parallelism 
	opportunities.

* ke2011safe - Safe Parallel programing Using Dynamic Dependence Hints
[Insights]
- Speculative parallelism divides sequential program into tasks
- A runtime environment resolve the task's dependences correctly in a way that it
might be executed sequentially or parallel, either way the program will be correct
- Most previous systems allow speculation to succeed only if program tasks are 
completely independent (also called do- all parallelism or embarrassingly parallel).
This one deals with frequent but not definite parallelism.
- Dependence hints: an interface (directives) for a user to suggest dependence between 
code.
[Similarities]
- We both deal with uncertain parallelism.
- We both deal with annotating techniques.
[Differences]
- Their technique doesn't seem to analyse the program statically.
- It is up to the PROGRAMMER to annotate the code with the speculative parallelism.

[PEDRO: INSIGHT I JUST HAD]
In the previous paper, they present a framework to annotate code that might be parallel.
So the programmer reads their code and annotate parts which can be parallel, and their runtime will
speculate over these annotated code. What WE'RE DOING is: we're analysing the code automatically to find
possible parallel sites, and then we annotate them correctly and finally the runtime resolves the dependences
and execute the tasks. The key insight in our work is to annotate code that is irregular but has
greater probability of being parallel during execution.

* Generating Task Clauses for OpenMP Programs
[Insights]
- They generate correct open MP task annotations for a code fragment
- They still rely on the programmer or the compiler to find this pieces of code
[Similarities]
- We both generate annotations for task-parallelism
[Differences]
- Our approach eases the burden on the programmer and finds parallel code automatically.

