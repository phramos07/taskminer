We thank the referees for all the time and expertise they have put into reviewing our work. We address individual comments below.

Review #124A

> The example in Figure 3 shows some limitations of the proposed
> TaskMiner approach as currently implemented. In particular, the
> generated code uses the if clause on the OpenMP task construct to
> limit generation of tasks. However, the if clause merely leads to the
> generation of an undeferred task. While the task must be executed
> immediately, most of the overheads of OpenMP task generation are still
> implied. In particular, the implementation must create a new data
> environment for the task. The correct way to end the task generation
> requires the use of the final clause, which leads to tasks that are
> mergeable and thus can be merged tasks, for which a data environment
> does not need to be created.

We agree with the referee: final tasking is a definitely better solution. However, none of the two compilers that we use support 'final+mergeable' (gcc and clang): they recognize the pragmas, but do not generate code for them. The 'if' clause is a temporary solution. Although not ideal, it brings noticeable runtime improvement. Fibonacci, our example in Figure 3 is 16x faster to calculate "fib 40" with the conditional pragma plus the task cutoff. Notice that our cost model already prevents the annotation of very small program regions.

> The authors do not discuss the restrictions of the depend clause on
> OpenMP Task constructs. In particular, "List items used in depend
> clauses of the same task or sibling tasks must indicate identical
> storage locations or disjoint storage locations." The implementation
> does not appear to consider this restriction so it is unclear if the
> automatically generated OpenMP tasking code is correct. This issue is
> significant as the proposed implementation may yield significantly
> higher parallelism as most OpenMP implementations only enforce
> dependencies based on the base address of an array section and will
> not detect that the restriction is violated (let alone enforce the
> intended dependences).

We consider the restriction on list items! We follow Section 2.13.9 of the standard. Even more, we only annotate a region if we can find symbolic limits for all the memory accesses used within that region. This restriction means that we only annotate arrays if we can determine their sections correctly. Another restriction is that a region must be profitable (see Page 10, Line 34, Column 1). Given these two restrictions, we found "annotable regions" in 63 out of 219 benchmarks in the LLVM test suite. All these benchmarks have sanity checks to certify correct behavior.

> Cilk++ is not annotation based. It's inclusion in the list of
> annotation systems in the first sentence of the introduction is
> incorrect.

The referee is right, and we shall fix the text.

> The default clause cannot be specified with the private parameter in C
> and C++. The private and firstprivate parameters are only permitted in
> Fortran.

We believe the referee refers to Page 4, Line 38, Column 2, where we wrote: "default([shared/private])". That was a bad way to write it. We do use private and firstprivate, but never within default. We shall fix that.

> The y-axis on Figure 10 needs to be labeled. What does the graph show?
> Runtime in seconds? Speedup? Compared to what? I think it is speedup
> compared to the sequential version of the program but it should be
> clearly indicated.

Yes, the referee's intuition is correct. We shall add labels to the figures.

> Including "bel-ford" as one of the three programs that most benefits
> from your cost model is not convincing since it appears to suffer from
> slowdown compared to the sequential version. That manual annotations
> provide even worse performance is irrelevant. Why doesn't your cost
> model determine that using tasks at all is a bad idea?

Some of the programs that we annotate do experiment slowdowns. That's a bit like compiling with gcc -O3, for instance: this optimization level slows downs some programs. The problem with bellman-ford, in particular, is not due to the cost model. This algorithm traverses a graph implemented as an array of arrays. The graph is not sparse, and dependences hinder parallelism. Actually dependences happen whenever two threads try to update the adjacent list of the same node. We experimented similar problems with other benchmarks that work with meshes of pointers (see Page 10, Line 53, Column 1).

Review #124B

> Comparing against manual parallel implementation makes sense, but I
> would appreciate to see alternative approaches as well (even ICC would
> at least give an idea).

We are comparing against gcc -O3, so, some of the benchmarks are vectorized by the compiler. The Swan benchmarks were taken from the Intel SPMD compiler. Thus, we can compare against them, if the referee wants. Notice that each one of these benchmarks is written in C and in SPMD. Only the latter is parallelized by ISPC (using vector instructions).

> In the evaluation section I would appreciate to see an evaluation of
> the cost model used in this work.

Figure 11 presented an evaluation in three benchmarks. We also would like to show numbers about some tuning of it. We did not do it due to lack of space, but we might include these results if we have one more page.

Review #124C

> Another thing that was not clear
> to me unless I miss something is how the algorithm determines where
> spawned tasks will be synchronized. The paper discusses how to find
> "program statements that can run in parallel with the rest of the
> program" (section 3.2), yet this notion is relative to when they
> synchronize with the rest of the program.

Yes, we acknowledge that we could have described it better. We use basically the same technique that nvcc uses to insert implicit barriers in programs: we synchronize at the post dominator of each parallel region.